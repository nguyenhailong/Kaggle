{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## PART 1:  Extract HOG features from images using scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: http://scikit-image.org/docs/dev/auto_examples/plot_hog.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_root = '/Volumes/My Passport/yelp/'\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage import io, data, color, exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_hog_features(image_path):\n",
    "    image = io.imread(image_path)\n",
    "    image = color.rgb2gray(image)\n",
    "    image_resized = resize(image, (256, 256))\n",
    "    return hog(image_resized, orientations=8,\n",
    "        pixels_per_cell=(16, 16), cells_per_block=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  234842\n",
      "Train images processed:  10000\n",
      "Train images processed:  20000\n",
      "Train images processed:  30000\n",
      "Train images processed:  40000\n",
      "Train images processed:  50000\n",
      "Train images processed:  60000\n",
      "Train images processed:  70000\n",
      "Train images processed:  80000\n",
      "Train images processed:  90000\n",
      "Train images processed:  100000\n",
      "Train images processed:  110000\n",
      "Train images processed:  120000\n",
      "Train images processed:  130000\n",
      "Train images processed:  140000\n",
      "Train images processed:  150000\n",
      "Train images processed:  160000\n",
      "Train images processed:  170000\n",
      "Train images processed:  180000\n",
      "Train images processed:  190000\n",
      "Train images processed:  200000\n",
      "Train images processed:  210000\n",
      "Train images processed:  220000\n",
      "Train images processed:  230000\n",
      "Train images processed:  234842\n",
      "\n",
      "Features extracted in 14866.624218s\n"
     ]
    }
   ],
   "source": [
    "# extract image features and save it to .h5\n",
    "\n",
    "# Initialize files\n",
    "import h5py\n",
    "f = h5py.File(data_root+'train_image_HOGfeatures.h5','w')\n",
    "filenames = f.create_dataset('photo_id',(0,), maxshape=(None,),dtype='|S54')\n",
    "feature = f.create_dataset('feature',(0,2048), maxshape = (None,2048))\n",
    "f.close()\n",
    "\n",
    "import pandas as pd \n",
    "train_photos = pd.read_csv(data_root+'train_photo_to_biz_ids.csv')\n",
    "train_folder = data_root+'train_photos/'\n",
    "train_images = [os.path.join(train_folder, str(x)+'.jpg') for x in train_photos['photo_id']]  # get full filename\n",
    "\n",
    "num_train = len(train_images)\n",
    "print \"Number of training images: \", num_train\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# Training Images\n",
    "for i in range(0, num_train):\n",
    "    feature = extract_hog_features(train_images[i])\n",
    "    num_done = i+1\n",
    "    f= h5py.File(data_root+'train_image_HOGfeatures.h5','r+')\n",
    "    f['photo_id'].resize((num_done,))\n",
    "    f['photo_id'][i] = train_images[i]\n",
    "    f['feature'].resize((num_done,feature.shape[0]))\n",
    "    f['feature'][i, :] = feature\n",
    "    f.close()\n",
    "    if num_done%10000==0 or num_done==num_train:\n",
    "        print \"Train images processed: \", num_done\n",
    "\n",
    "toc = time.time()\n",
    "print '\\nFeatures extracted in %fs' % (toc - tic)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_features.h5:\n",
      "feature (234842, 2048)\n",
      "photo_id (234842,)\n",
      "\n",
      "A photo: /Volumes/My Passport/yelp/train_photos/204149.jpg\n",
      "Its feature vector (first 10-dim):  [ 0.34791261  0.0733768   0.01276903  0.00645388  0.15348932  0.09106192\n",
      "  0.04581008  0.26656917  0.04787623  0.01552287]  ...\n"
     ]
    }
   ],
   "source": [
    "### Check the file content\n",
    "\n",
    "f = h5py.File(data_root+'train_image_HOGfeatures.h5','r')\n",
    "print 'train_image_features.h5:'\n",
    "for key in f.keys():\n",
    "    print key, f[key].shape\n",
    "    \n",
    "print \"\\nA photo:\", f['photo_id'][0]\n",
    "print \"Its feature vector (first 10-dim): \", f['feature'][0][0:10], \" ...\"\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature from test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images:  237152\n",
      "Test images processed:  20000\n",
      "Test images processed:  40000\n",
      "Test images processed:  60000\n",
      "Test images processed:  80000\n",
      "Test images processed:  100000\n",
      "Test images processed:  120000\n",
      "Test images processed:  140000\n",
      "Test images processed:  160000\n",
      "Test images processed:  180000\n",
      "Test images processed:  200000\n",
      "Test images processed:  220000\n",
      "Test images processed:  237152\n",
      "\n",
      "Features extracted in 15702.819823s\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(data_root+'test_image_HOGfeatures.h5','w')\n",
    "filenames = f.create_dataset('photo_id',(0,), maxshape=(None,),dtype='|S54')\n",
    "feature = f.create_dataset('feature',(0,2048), maxshape = (None,2048))\n",
    "f.close()\n",
    "\n",
    "test_photos = pd.read_csv(data_root+'test_photo_to_biz.csv')\n",
    "test_folder = data_root+'test_photos/'\n",
    "test_images = [os.path.join(test_folder, str(x)+'.jpg') for x in test_photos['photo_id'].unique()]\n",
    "\n",
    "num_test = len(test_images)\n",
    "print \"Number of test images: \", num_test\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# Test Images\n",
    "for i in range(0, num_test):\n",
    "    feature = extract_hog_features(test_images[i])\n",
    "    num_done = i+1\n",
    "    f= h5py.File(data_root+'test_image_HOGfeatures.h5','r+')\n",
    "    f['photo_id'].resize((num_done,))\n",
    "    f['photo_id'][i] = test_images[i]\n",
    "    f['feature'].resize((num_done,feature.shape[0]))\n",
    "    f['feature'][i, :] = feature\n",
    "    f.close()\n",
    "    if num_done%20000==0 or num_done==num_test:\n",
    "        print \"Test images processed: \", num_done\n",
    "\n",
    "toc = time.time()\n",
    "print '\\nFeatures extracted in %fs' % (toc - tic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Check the file content\n",
    "f = h5py.File(data_root+'test_image_HOGfeatures.h5','r')\n",
    "print 'test_image_features.h5:'\n",
    "for key in f.keys():\n",
    "    print key, f[key].shape\n",
    "    \n",
    "print \"\\nA photo:\", f['photo_id'][0]\n",
    "print \"Its feature vector (first 10-dim): \", f['feature'][0][0:10], \" ...\"\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
