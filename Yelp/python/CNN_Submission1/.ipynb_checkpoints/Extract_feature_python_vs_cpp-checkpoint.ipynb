{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the features extracted from Python Wrapper V.S. C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Extract Features with Caffe Python wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is modified from https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5-dim of predicted probability is \n",
      " #[  1.19005195e-09   1.75350069e-05   2.98270955e-08   1.97281977e-08\n",
      "   6.59751453e-09].\n",
      "\n",
      " Top 5 classes: \n",
      "['n02123045 tabby, tabby cat' 'n02123159 tiger cat'\n",
      " 'n02124075 Egyptian cat' 'n02119022 red fox, Vulpes vulpes'\n",
      " 'n02127052 lynx, catamount']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "\n",
    "import os\n",
    "if not os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print(\"Downloading pre-trained CaffeNet model...\")\n",
    "    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet\n",
    "    \n",
    "caffe.set_mode_cpu()\n",
    "net = caffe.Net(caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt',\n",
    "                caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel',\n",
    "                caffe.TEST)\n",
    "\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))#\n",
    "transformer.set_mean('data', np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "net.blobs['data'].reshape(1,3,227,227)\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', caffe.io.load_image(caffe_root + 'examples/images/cat.jpg'))\n",
    "out = net.forward()\n",
    "print(\"First 5-dim of predicted probability is \\n #{}.\".format(out['prob'][0][0:5]))\n",
    "\n",
    "# load labels\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "try:\n",
    "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "except:\n",
    "    !../data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "\n",
    "# sort top k predictions from softmax output\n",
    "top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "print \"\\n Top 5 classes: \\n\", labels[top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Read features extracted from C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I extracted feature from the same image (cat.jpg) following the instruction \n",
    "http://caffe.berkeleyvision.org/gathered/examples/feature_extraction.html\n",
    "with minor modifications:\n",
    "\n",
    "(1)(2) are not necessary. I did it just to make sure the features extracted come from \"cat.jpg\" and not other images. <br>\n",
    "(1) In the file \"caffe/examples/_temp/file_list.txt\", I remove the other two images and keep only cat.jpg.  <br>\n",
    "(2) In the file \"caffe/examples/_temp/imagenet_val.prototxt\", change batch_size to 1 <br>\n",
    "(3) Run: ./build/tools/extract_features.bin models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel  examples/_temp/imagenet_val.prototxt prob examples/_temp/features 1 lmdb GPU <br>\n",
    "So that probability-layer is used instead of fc7, only 1 feature is extracted, is saved in lmdb format, and use GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This code is modified from \n",
    "## http://stackoverflow.com/questions/33117607/caffe-reading-lmdb-from-python\n",
    "\n",
    "import caffe\n",
    "import lmdb\n",
    "import numpy as np\n",
    "from caffe.proto import caffe_pb2\n",
    "caffe_root = '../'\n",
    "def save2txt(db_name):\n",
    "    img_db = lmdb.open(db_name)\n",
    "    txn = img_db.begin()\n",
    "    cursor = txn.cursor()\n",
    "    cursor.iternext()\n",
    "    \n",
    "    count = 0\n",
    "    train={}\n",
    "    \n",
    "    datum = caffe_pb2.Datum()\n",
    "    count = 0\n",
    "    train={}\n",
    "    for key, value in cursor:\n",
    "        datum.ParseFromString(value)\n",
    "        data = caffe.io.datum_to_array(datum)\n",
    "        data = np.reshape(data, (1, np.product(data.shape)))[0]\n",
    "        train[count]=data\n",
    "        count +=1    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5-dim of (probability) feature vector: \n",
      "[  7.86413157e-09   2.60096385e-05   4.55995348e-08   5.70442324e-08\n",
      "   2.98107672e-08]\n"
     ]
    }
   ],
   "source": [
    "prob_feature=save2txt('/home/ncchen/caffe/examples/_temp/features/')\n",
    "print \"The first 5-dim of (probability) feature vector: \\n\", prob_feature[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 5 classes: \n",
      "['n02123045 tabby, tabby cat' 'n02124075 Egyptian cat'\n",
      " 'n02123159 tiger cat' 'n02127052 lynx, catamount'\n",
      " 'n02119789 kit fox, Vulpes macrotis']\n"
     ]
    }
   ],
   "source": [
    "top_k = prob_feature[0].flatten().argsort()[-1:-6:-1]\n",
    "print \"\\n Top 5 classes: \\n\", labels[top_k]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
